services:
  mongodb:
    image: mongo:latest
    container_name: mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: 'root'
      MONGO_INITDB_ROOT_PASSWORD: "123456"
      TZ: $TZ
    #      wiredTigerCacheSizeGB: 2
    volumes:
      - ${DATA_DIR}/mongo:/data/db:rw
      - ${DATA_DIR}/mongo_key:/mongo:rw
    ports:
      - "27017:27017"
    restart: always
    networks:
      - default
    command:
      --auth

  postgresql16:
    image: postgres:16 # 指定版本
    container_name: postgresql
    privileged: true #解决权限问题
    ports:
      - "5432:5432"
    volumes:
      - ${DATA_DIR}/pgsql:/var/lib/postgresql/data:rw
    environment:
      POSTGRES_USER: root # 从环境变量读取
      POSTGRES_PASSWORD: root # 从环境变量读取
      POSTGRES_DB: test # 指定数据库名称
      TZ: ${TZ}
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB" ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    networks:
      - default

  mysql8:
    image: mysql:8
    container_name: mysql8
    ports:
      - "13306:3306"
    volumes:
      - ${DATA_DIR}/mysql8:/var/lib/mysql/:rw
    restart: always
    networks:
      - default
    environment:
      MYSQL_ROOT_PASSWORD: 'root'
      MYSQL_ROOT_HOST: '%'
      TZ: $TZ

  myRedis:
    image: redis:latest
    container_name: myredis
    restart: unless-stopped
    environment:
      - TZ=Asia/Shanghai
    ports:
      - '6379:6379'
    volumes:
      - ${DATA_DIR}/redis/conf:/usr/local/etc/redis:rw
      - ${DATA_DIR}/redis:/data/:rw
    command:
      redis-server --port 6379 --requirepass "123456" --appendonly yes
    networks:
      - default

  etcd:
    image: bitnami/etcd:latest
    container_name: etcd
    ports:
      - "2379:2379"
      - "2380:2380"
    volumes:
      - ${DATA_DIR}/etcd:/bitnami/etcd/data/:rw
    restart: always
    environment:
      ALLOW_NONE_AUTHENTICATION: yes
      TZ: ${TZ}
    networks:
      - default

  kafka:
    image: docker.chenby.cn/bitnami/kafka:3.5.2
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      TZ: ${TZ}
      # KRaft settings
      KAFKA_CFG_NODE_ID: 1
      KAFKA_CFG_PROCESS_ROLES: controller,broker
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093 # 单节点 KRaft 模式配置
      KAFKA_KRAFT_CLUSTER_ID: abcdefghijklmnopqrstuv
      # Listeners
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://127.0.0.1:9092 #外网访问地址
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      # Clustering
      KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR: 1
    volumes:
      - ${DATA_DIR}/kafka:/bitnami/kafka:rw
    restart: always
    networks:
      - default

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    container_name: elasticsearch
    environment:
      - TZ=$TZ
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false # 禁用安全功能
      - cluster.initial_master_nodes=elasticsearch # 单节点集群
      - ES_PATH_LOG=/usr/share/elasticsearch/logs # 指定日志路径
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ${DATA_DIR}/esData:/usr/share/elasticsearch/data:rw
      - ${DATA_DIR}/esLog:/usr/share/elasticsearch/logs:rw # 新增日志目录映射
    ports:
      - '9200:9200'
    networks:
      - default
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=30s" ]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: on-failure # 当容器异常退出时重启

  logstash:
    image: docker.elastic.co/logstash/logstash:8.15.0
    container_name: logstash
    ports:
      - '5044:5044'
      - '9600:9600' # 添加 Logstash API 端口映射
    depends_on:
      - elasticsearch
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail http://elasticsearch:9200 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    networks:
      - default

  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.0
    container_name: kibana
    ports:
      - '5601:5601'
    depends_on:
      - elasticsearch
    networks:
      - default
    restart: always
    environment:
      TZ: "Asia/Shanghai"
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
      I18N_LOCALE: "zh-CN"
      SERVER_TIMEOUT: 300s  # 尝试增加到 300 秒
      XPACK_ALERTING_MAX_INSTALL_TIME: 1800000ms  # 尝试增加到 1800000 毫秒
      # 确保 Elasticsearch 已准备好接受请求
      ELASTICSEARCH_WAIT_FOR: yellow


networks:
  default:
    driver: bridge
    ipam:
      driver: default
      # 解除下面的注释可以设置网段，用于nginx等容器固定容器IP
      #config:
      #  - subnet: 10.0.0.0/24
